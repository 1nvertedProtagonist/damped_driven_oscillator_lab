{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import labtools as lbts\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.signal import find_peaks, argrelmin\n",
    "import os \n",
    "import argparse\n",
    "import importlib, labtools\n",
    "importlib.reload(labtools)\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First do step one of the investigation, find the natural frequency of \n",
    "## oscillations. First, mainly find the period of oscillations while only\n",
    "## damped but not driven, solve for the \\beta value (as defined in lab manual)\n",
    "## get natural frequency and make conclusion of oserved underdamping. \\beta might be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa68a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take and process data from not driven but damped oscillator\n",
    "## sort it out into what we need.\n",
    "\n",
    "\n",
    "nodrR1 =np.genfromtxt(\"nodrR1.csv\", delimiter = \",\",comments = \"%\" ,skip_header =0) \n",
    "nodrR2 =np.genfromtxt(\"nodrR2.csv\", delimiter = \",\",comments = \"%\" ,skip_header =0)\n",
    "nodrR3 = np.genfromtxt(\"nodrR3.csv\", delimiter = \",\", comments =\"%\",skip_header =0)\n",
    "nodrR4 = np.genfromtxt(\"nodrR4.csv\", delimiter = \",\", comments = \"%\", skip_header =0)\n",
    "nodrR5 = np.genfromtxt(\"nodrR5.csv\", delimiter = \",\", comments = \"%\", skip_header =0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_runs= [nodrR1,nodrR2, nodrR3, nodrR4, nodrR5]\n",
    "\n",
    "for i in range(len(raw_runs)): \n",
    "  #print(raw_runs[i].shape)\n",
    "  None\n",
    "\n",
    "\n",
    "sliced_runs = []\n",
    "for i in range(len(raw_runs)): \n",
    "  a= np.asarray(raw_runs[i][0:1475,:]) \n",
    "  sliced_runs.append(a)\n",
    "  \n",
    "  #plt.plot(a[:,0],a[:,1])\n",
    "  #plt.xlabel(\"time\")\n",
    "  #plt.ylabel(\"driving\")\n",
    "  #plt.title(f\"run number {i+1}\")\n",
    "  #plt.show()\n",
    "\n",
    "  #plt.plot(a[:,0], a[:,2])\n",
    "  #plt.xlabel(\"time\")\n",
    "  #plt.ylabel(\"pos vol\")\n",
    "  #plt.title(f\"run number {i+1}\")\n",
    "  #plt.show()\n",
    "\n",
    "## VERY IMPORTANT\n",
    "## column 1 is drive wave\n",
    "## column 2 is motion wave\n",
    "## this goes for all the files\n",
    "\n",
    "## time to find out natural frequency\n",
    "#print(type(sliced_runs))\n",
    "#print(len(sliced_runs))\n",
    "#for i in range(len(sliced_runs)): \n",
    "  #print(f\"{sliced_runs[i].shape} is the shape of run number {i}\")\n",
    "\n",
    "## Step number 1, find out the time intervals at which peaks and troughs\n",
    "## occur, also take the opportunity to extract the voltage signals (y values)\n",
    "## at these moments\n",
    "## code below is for peak-to-peak analysis\n",
    "\n",
    "lisfinxmxvals = []\n",
    "lisfinymxvals = []\n",
    "for i in range(len(sliced_runs)): \n",
    "  #print(sliced_runs[i].shape)\n",
    "  plt.plot(sliced_runs[i][:,0], sliced_runs[i][:,2])\n",
    "  plt.xlabel(\"time\")\n",
    "  plt.ylabel(\"pos vol\")\n",
    "  plt.title(f\"run number {i+1}\")\n",
    "  plt.show()\n",
    "  indpeakrun = find_peaks(sliced_runs[i][:,2],height=1.45,distance=15)[0]\n",
    "  #print(f\"{sliced_runs[i][:,2].shape} is the shape of displacement run number {i}\")\n",
    "  #print(f\"{indpeakrun.shape} is the shape of indpeakrun {i}\")\n",
    "  #print(type(indpeakrun))\n",
    "  #print(type(indpeakrun))\n",
    "  #print(type(indpeakrun[0]))\n",
    "  lisxvals = []\n",
    "  lisyvals = []\n",
    "  #print(len(indpeakrun))\n",
    "  for j in range(len(indpeakrun)): \n",
    "    pos = indpeakrun[j]\n",
    "    #print((pos))\n",
    "    #print(sliced_runs[i].shape)\n",
    "    xval = sliced_runs[i][:,0][pos]\n",
    "    yval = sliced_runs[i][:,2][pos]\n",
    "    lisxvals.append(xval)\n",
    "    lisyvals.append(yval)\n",
    "  runxval = np.asarray(lisxvals)\n",
    "  runyval = np.asarray(lisyvals)\n",
    "  lisfinxmxvals.append(runxval)\n",
    "  lisfinymxvals.append(runyval)\n",
    "\n",
    "#print(type(lisfinxvals))\n",
    "#print(type(lisfinxvals[0]))\n",
    "#print(len(sliced_runs[0][:,2]))\n",
    "#print(sliced_runs[0][:,2].shape)\n",
    "#print(sliced_runs[0][:,2].size)\n",
    "#print(sliced_runs[0].size)\n",
    "#print(sliced_runs[0].shape)\n",
    "#print((lisfinxmxvals[0]))\n",
    "#print(lisfinymxvals[0])\n",
    "#print(lisfinxmxvals[1])\n",
    "#print(lisfinymxvals[1])\n",
    "\n",
    "## Now extract the same thing, but go trough to trough\n",
    "\n",
    "lisfinxmnvals = []\n",
    "lisfinymnvals = []\n",
    "for i in range(len(sliced_runs)): \n",
    "  #print(sliced_runs[i].shape)\n",
    "  #plt.plot(sliced_runs[i][:,0], sliced_runs[i][:,2])\n",
    "  #plt.xlabel(\"time\")\n",
    "  #plt.ylabel(\"pos vol\")\n",
    "  #plt.title(f\"run number {i+1}\")\n",
    "  #plt.show()\n",
    "  indpeakrun = argrelmin(sliced_runs[i][:,2],order=15)[0]\n",
    "  #print(f\"{sliced_runs[i][:,2].shape} is the shape of displacement run number {i}\")\n",
    "  #print(f\"{indpeakrun.shape} is the shape of indpeakrun {i}\")\n",
    "  #print(type(indpeakrun))\n",
    "  #print(type(indpeakrun))\n",
    "  #print(type(indpeakrun[0]))\n",
    "  lisxvals = []\n",
    "  lisyvals = []\n",
    "  #print(len(indpeakrun))\n",
    "  for j in range(len(indpeakrun)): \n",
    "    pos = indpeakrun[j]\n",
    "    #print((pos))\n",
    "    #print(sliced_runs[i].shape)\n",
    "    xval = sliced_runs[i][:,0][pos]\n",
    "    yval = sliced_runs[i][:,2][pos]\n",
    "    lisxvals.append(xval)\n",
    "    lisyvals.append(yval)\n",
    "  runxval = np.asarray(lisxvals)\n",
    "  runyval = np.asarray(lisyvals)\n",
    "  mask = runyval < 1.392\n",
    "  filrunxvals = runxval[mask]\n",
    "  filrunyvals = runyval[mask]\n",
    "  lisfinxmnvals.append(filrunxvals)\n",
    "  lisfinymnvals.append(filrunyvals)\n",
    "\n",
    "for i in range(len(lisfinxmxvals)): \n",
    "  print(f\"this thing has a period of {np.diff(lisfinxmxvals[i])}\")\n",
    "\n",
    "for i in range(len(lisfinxmnvals)): \n",
    "  print(f\"this thing has a period of {np.diff(lisfinxmnvals[i])}\")\n",
    "#print(lisfinxmnvals[0])\n",
    "#print(lisfinymnvals[0])\n",
    "#print(lisfinxmnvals[1])\n",
    "#print(lisfinymxvals[0])\n",
    "\n",
    "## data sorted succesfully. now proceed to find damped freq. \n",
    "## and \\beta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding the damped oscillator angular frequency\n",
    "\n",
    "damped_freqsmx = []\n",
    "for i in range(len(lisfinxmxvals)): \n",
    "  runfreqs = (2*np.pi)/np.diff(lisfinxmxvals[i])\n",
    "  damped_freqsmx.append(runfreqs)\n",
    "\n",
    "damped_freqmn = []\n",
    "for i in range(len(lisfinxmnvals)): \n",
    "  runfreqs = (2*np.pi)/np.diff(lisfinxmnvals[i])\n",
    "  damped_freqmn.append(runfreqs)\n",
    "\n",
    "mx_means = []\n",
    "mx_uncs = []\n",
    "for i in range(len(damped_freqsmx)): \n",
    "  a=lbts.find_plottabl_stuff(damped_freqsmx[i])\n",
    "  mx_means.append(a[0])\n",
    "  mx_uncs.append(a[1])\n",
    "\n",
    "mx_means = np.asarray(mx_means)\n",
    "mx_uncs = np.asarray(mx_uncs)\n",
    "\n",
    "mn_means = []\n",
    "mn_uncs = []\n",
    "#print(damped_freqmn)\n",
    "for i in range(len(damped_freqmn)): \n",
    "  b = lbts.find_plottabl_stuff(damped_freqmn[i])\n",
    "  mn_means.append(b[0])\n",
    "  mn_uncs.append(b[1]) \n",
    "\n",
    "mn_means = np.asarray(mn_means)\n",
    "mn_uncs = np.asarray(mn_uncs) \n",
    "\n",
    "#print(mn_means)\n",
    "#print(mn_uncs)\n",
    "\n",
    "finfreqmx = lbts.weighted_mean(mx_means, mx_uncs)\n",
    "finfreqmn = lbts.weighted_mean(mn_means, mn_uncs)\n",
    "\n",
    "fin_mean = np.asarray([finfreqmx[0],finfreqmn[0]])\n",
    "fin_uncs = np.asarray([finfreqmx[1],finfreqmn[1]])\n",
    "\n",
    "FIN_dmpfreqmean = lbts.weighted_mean(fin_mean,fin_uncs)[0]\n",
    "FIN_dmpfrequnc = lbts.weighted_mean(fin_mean, fin_uncs)[1]\n",
    "\n",
    "print(FIN_dmpfreqmean)\n",
    "print(FIN_dmpfrequnc)\n",
    "print(FIN_dmpfreqmean/(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before doing any ratio divsion of any sort (to solve for beta), we \n",
    "## have to calibrate remove the voltage offset from signals.\n",
    "\n",
    "raw_offset = np.genfromtxt(\"offset_calibration.csv\",delimiter = \",\", comments = \"%\",skip_header=0)\n",
    "mean_offset = np.mean(raw_offset[:,2],axis=0)\n",
    "mea_offset_unc = lbts.SEM(raw_offset[:,2],axis =0)\n",
    "\n",
    "print(mean_offset)\n",
    "print(mea_offset_unc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5184de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT RUN THIS CELL WITHOUT RUNNING ALL ONES ABOVE AS WELL IN ORDER\n",
    "## VERY IMPORTANT!!!!!!!!! \n",
    "\n",
    "## solve for beta\n",
    "## removing the voltage offset\n",
    "\n",
    "\n",
    "for i in range(len(lisfinymxvals)): \n",
    "  lisfinymxvals[i] += -mean_offset \n",
    "\n",
    "#print(lisfinymxvals)\n",
    "\n",
    "for i in range(len(lisfinymnvals)): \n",
    "  lisfinymnvals[i]+= -mean_offset\n",
    "betamxs = []\n",
    "for i in range(len(lisfinymxvals)): \n",
    "  a= np.log(((lisfinymxvals[i][1:])/\n",
    "                                                   lisfinymxvals[i][0:-1]))\n",
    "  betamx = (1/np.diff(lisfinxmxvals[i])) * a\n",
    "  #print(a<0)\n",
    "  betamxrun = np.mean(betamx)\n",
    "  betamxs.append(betamxrun)\n",
    "betamxs = np.asarray(betamxs)\n",
    "\n",
    "betamns = []\n",
    "for i in range(len(lisfinymnvals)): \n",
    "  betamn = (1/np.diff(lisfinxmnvals[i]))* (np.log((lisfinymnvals[i][1:])/\n",
    "                                                  (lisfinymnvals[i][0:-1])))\n",
    "  betamnrun = np.mean(betamn)\n",
    "  betamns.append(betamnrun)\n",
    "betamns= np.asarray(betamns)\n",
    "\n",
    "#print(np.mean(betamxs))\n",
    "#print(lbts.SEM(betamxs))\n",
    "#print(np.mean(betamns))\n",
    "#print(lbts.SEM(betamns))\n",
    "\n",
    "finbeta = lbts.weighted_mean(np.asarray([np.mean(betamxs),np.mean(betamns)]),\n",
    "                             np.asarray([lbts.SEM(betamxs),lbts.SEM(betamns)]))[0]\n",
    "finbetaunc = lbts.weighted_mean(np.asarray([np.mean(betamxs),np.mean(betamns)]),\n",
    "                             np.asarray([lbts.SEM(betamxs),lbts.SEM(betamns)]))[1]\n",
    "\n",
    "print(finbeta)\n",
    "print(finbetaunc)\n",
    "## note that here beta was kept negative (decay nature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate nartural freq, with uncertianty\n",
    "## observs that beta <0 and beta < freq damped\n",
    "\n",
    "omega0 = np.sqrt(finbeta**2+FIN_dmpfreqmean**2)\n",
    "\n",
    "unc_omega0 = np.sqrt((finbetaunc**2)*((finbeta**2)/(FIN_dmpfreqmean**2+finbeta**2))+ \n",
    "                     (FIN_dmpfrequnc**2)* FIN_dmpfreqmean**2/(FIN_dmpfreqmean**2+finbeta**2))\n",
    "\n",
    "print(omega0)\n",
    "print(unc_omega0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWOPI = 2*np.pi\n",
    "\n",
    "## functions to transcribe the csvs into data\n",
    "\n",
    "def parse_frequency_from_name(name: str) -> float:\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(mHz|Hz)', name, re.IGNORECASE)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Could not parse frequency from filename: {name}\")\n",
    "    val = float(m.group(1))\n",
    "    unit = m.group(2).lower()\n",
    "    return val/1000.0 if unit == \"mhz\" else val\n",
    "\n",
    "def find_data_start(path: Path, npeek: int = 200) -> int:\n",
    "    with open(path, \"r\", errors=\"ignore\") as f:\n",
    "        lines = []\n",
    "        for _ in range(npeek):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            lines.append(line)\n",
    "    for i, line in enumerate(lines):\n",
    "        parts = [p.strip() for p in line.strip().split(\",\")]\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            float(parts[0]); float(parts[1]); float(parts[2])\n",
    "            return i\n",
    "        except Exception:\n",
    "            continue\n",
    "    return 0\n",
    "\n",
    "def parse_fs_from_header(path: Path, fallback: float = 200.0) -> float:\n",
    "    with open(path, \"r\", errors=\"ignore\") as f:\n",
    "        for _ in range(140):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            m = re.search(r'Acquisition rate:\\s*([0-9.+-eE]+)\\s*Hz', line)\n",
    "            if m:\n",
    "                return float(m.group(1))\n",
    "    return float(fallback)\n",
    "\n",
    "def read_three_col_csv_with_fs(path: Path) -> tuple[pd.DataFrame, float]:\n",
    "    skip = find_data_start(path)\n",
    "    fs = parse_fs_from_header(path)\n",
    "    df = pd.read_csv(path, header=None, skiprows=skip)\n",
    "    if df.shape[1] < 3:\n",
    "        raise ValueError(f\"{path.name}: expected >=3 columns, got {df.shape[1]}\")\n",
    "    df = df.iloc[:, :3].copy()\n",
    "    df.columns = [\"t_raw\", \"drive\", \"resp\"]\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "\n",
    "    # Reconstruct time using fs to avoid rounding artifacts in t_raw:\n",
    "    N = df.shape[0]\n",
    "    t = np.arange(N) / fs\n",
    "    out = pd.DataFrame({\"t\": t, \"drive\": df[\"drive\"].to_numpy(), \"resp\": df[\"resp\"].to_numpy()})\n",
    "    return out, fs\n",
    "\n",
    "\n",
    "## time domain functions\n",
    "\n",
    "def lin_sine_fit(t: np.ndarray, y: np.ndarray, f_hz: float) -> dict:\n",
    "    \"\"\"TD fit: y = B sin(ωt) + D cos(ωt) + C (ω fixed).\"\"\"\n",
    "    w = TWOPI*f_hz\n",
    "    X = np.column_stack([np.sin(w*t), np.cos(w*t), np.ones_like(t)])\n",
    "    coef, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    B, D, C0 = coef\n",
    "    A = float(np.hypot(B, D))\n",
    "    phi = float(np.arctan2(D, B) % TWOPI)\n",
    "    return {\"A\": A, \"phi\": phi, \"C\": float(C0)}\n",
    "\n",
    "def fft_projection_at_f(t: np.ndarray, y: np.ndarray, f_hz: float) -> dict:\n",
    "    \"\"\"Fourier method: single-frequency projection at exact f.\"\"\"\n",
    "    y0 = y - np.mean(y)\n",
    "    w = TWOPI*f_hz\n",
    "    N = len(y0)\n",
    "    Z = (2.0/N) * np.sum(y0 * np.exp(-1j*w*t))\n",
    "    return {\"A\": float(np.abs(Z)), \"phi\": float(np.angle(Z) % TWOPI)}\n",
    "\n",
    "def circular_mean_sem(phases: list[float]) -> tuple[float, float]:\n",
    "    phases = np.asarray(phases, dtype=float)\n",
    "    z = np.exp(1j*phases)\n",
    "    m = z.mean()\n",
    "    mean_angle = float(np.angle(m) % TWOPI)\n",
    "    R = abs(m)\n",
    "    circ_std = float(np.sqrt(-2*np.log(max(R, 1e-12))))\n",
    "    sem = circ_std/np.sqrt(len(phases)) if len(phases) > 1 else np.nan\n",
    "    return mean_angle, sem\n",
    "\n",
    "def chunk_indices_cycles(N: int, fs: float, f_hz: float, cycles_per_chunk: float = 2.0, min_seconds: float = 2.0):\n",
    "    \"\"\"Split file into non-overlapping chunks so SEM can be computed.\"\"\"\n",
    "    chunk_s = max(min_seconds, cycles_per_chunk/max(f_hz, 1e-12))\n",
    "    L = int(round(fs*chunk_s))\n",
    "    L = max(L, 20)\n",
    "    if N // L < 3:\n",
    "        min_cycles = 1.5\n",
    "        L_min = int(round(fs*(min_cycles/max(f_hz,1e-12))))\n",
    "        L = max(L_min, N//3) if N//3 >= L_min else max(L_min, N//2)\n",
    "    n_chunks = max(1, N // L)\n",
    "    L = N // n_chunks\n",
    "    starts = [i*L for i in range(n_chunks)]\n",
    "    L_min = int(round(fs*(1.5/max(f_hz,1e-12))))\n",
    "    return [(s, s+L) for s in starts if (s+L - s) >= L_min]\n",
    "\n",
    "# ----------------------------\n",
    "# Plot / table helpers\n",
    "# ----------------------------\n",
    "def phase_ticks(ax, axis='y'):\n",
    "    ticks = [0, np.pi/2, np.pi, 3*np.pi/2, 2*np.pi]\n",
    "    labels = [\"0\", r\"$\\pi/2$\", r\"$\\pi$\", r\"$3\\pi/2$\", r\"$2\\pi$\"]\n",
    "    if axis == 'y':\n",
    "        ax.set_yticks(ticks, labels)\n",
    "        ax.set_ylim(0, 2*np.pi)\n",
    "    else:\n",
    "        ax.set_xticks(ticks, labels)\n",
    "        ax.set_xlim(0, 2*np.pi)\n",
    "\n",
    "def format_pm(val: float, err: float, sig: int = 2) -> str:\n",
    "    if pd.isna(err) or err == 0:\n",
    "        return f\"{val:.6g}\"\n",
    "    e = int(np.floor(np.log10(abs(err)))) if err != 0 else 0\n",
    "    decimals = max(0, -(e) + (sig-1))\n",
    "    err_r = round(err, decimals)\n",
    "    val_r = round(val, decimals)\n",
    "    if abs(val_r) >= 1e4 or abs(val_r) < 1e-3:\n",
    "        return f\"{val_r:.{sig}e} \\\\pm {err_r:.{sig}e}\"\n",
    "    return f\"{val_r:.{decimals}f} \\\\pm {err_r:.{decimals}f}\"\n",
    "\n",
    "def df_to_latex_table(df: pd.DataFrame, caption: str, label: str, col_spec: str, headers: list[str]) -> str:\n",
    "    lines=[]\n",
    "    lines.append(\"\\\\begin{table}[h!]\")\n",
    "    lines.append(\"\\\\centering\")\n",
    "    lines.append(f\"\\\\caption{{{caption}}}\")\n",
    "    lines.append(f\"\\\\label{{{label}}}\")\n",
    "    lines.append(f\"\\\\begin{{tabular}}{{{col_spec}}}\")\n",
    "    lines.append(\"\\\\hline\")\n",
    "    lines.append(\" & \".join(headers) + \" \\\\\\\\\")\n",
    "    lines.append(\"\\\\hline\")\n",
    "    for _, r in df.iterrows():\n",
    "        lines.append(\" & \".join(r.tolist()) + \" \\\\\\\\\")\n",
    "    lines.append(\"\\\\hline\")\n",
    "    lines.append(\"\\\\end{tabular}\")\n",
    "    lines.append(\"\\\\end{table}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "##batch zoom selection, either coarse, medium or fine\n",
    "\n",
    "def choose_one_file_per_frequency(files: list[Path]) -> list[Path]:\n",
    "    \"\"\"If duplicates exist at same frequency, prefer '(in)' filenames.\"\"\"\n",
    "    by_f: dict[float, Path] = {}\n",
    "    for p in files:\n",
    "        f = parse_frequency_from_name(p.name)\n",
    "        if f not in by_f:\n",
    "            by_f[f] = p\n",
    "        else:\n",
    "            if \"(in)\" in p.name and \"(in)\" not in by_f[f].name:\n",
    "                by_f[f] = p\n",
    "    return [by_f[f] for f in sorted(by_f.keys())]\n",
    "\n",
    "def select_files_in_range(folder: Path, fmin: float, fmax: float) -> list[Path]:\n",
    "    all_csvs = sorted(folder.glob(\"*.csv\"))\n",
    "    in_range = []\n",
    "    for p in all_csvs:\n",
    "        try:\n",
    "            f = parse_frequency_from_name(p.name)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if (fmin - 1e-12) <= f <= (fmax + 1e-12):\n",
    "            in_range.append(p)\n",
    "    return choose_one_file_per_frequency(in_range)\n",
    "\n",
    "\n",
    "## all necessary computations for selected batch\n",
    "\n",
    "\n",
    "def process_batch(files: list[Path]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for path in files:\n",
    "        f_hz = parse_frequency_from_name(path.name)\n",
    "        df, fs = read_three_col_csv_with_fs(path)\n",
    "        t = df[\"t\"].to_numpy()\n",
    "        drive = df[\"drive\"].to_numpy()\n",
    "        resp = df[\"resp\"].to_numpy()\n",
    "\n",
    "        chunks = chunk_indices_cycles(len(t), fs, f_hz)\n",
    "\n",
    "        A_td_list, d_td_list = [], []\n",
    "        A_f_list, d_f_list, H_list = [], [], []\n",
    "        for a, b in chunks:\n",
    "            fd = lin_sine_fit(t[a:b], drive[a:b], f_hz)\n",
    "            fr = lin_sine_fit(t[a:b], resp[a:b], f_hz)\n",
    "            A_td_list.append(fr[\"A\"])\n",
    "            d_td_list.append((fr[\"phi\"] - fd[\"phi\"]) % TWOPI)\n",
    "\n",
    "            od = fft_projection_at_f(t[a:b], drive[a:b], f_hz)\n",
    "            orr = fft_projection_at_f(t[a:b], resp[a:b], f_hz)\n",
    "            A_f_list.append(orr[\"A\"])\n",
    "            d_f_list.append((orr[\"phi\"] - od[\"phi\"]) % TWOPI)\n",
    "            H_list.append(orr[\"A\"]/od[\"A\"] if od[\"A\"] > 0 else np.nan)\n",
    "\n",
    "        A_td_mean = float(np.mean(A_td_list))\n",
    "        A_td_sem  = float(np.std(A_td_list, ddof=1)/np.sqrt(len(A_td_list))) if len(A_td_list) > 1 else np.nan\n",
    "        d_td_mean, d_td_sem = circular_mean_sem(d_td_list)\n",
    "\n",
    "        A_f_mean = float(np.mean(A_f_list))\n",
    "        A_f_sem  = float(np.std(A_f_list, ddof=1)/np.sqrt(len(A_f_list))) if len(A_f_list) > 1 else np.nan\n",
    "        d_f_mean, d_f_sem = circular_mean_sem(d_f_list)\n",
    "\n",
    "        H_mean = float(np.nanmean(H_list))\n",
    "\n",
    "        rows.append({\n",
    "            \"file\": path.name,\n",
    "            \"f_Hz\": f_hz,\n",
    "            \"A_TD_V\": A_td_mean,\n",
    "            \"A_TD_SEM_V\": A_td_sem,\n",
    "            \"delta_TD_rad\": d_td_mean,\n",
    "            \"delta_TD_SEM_rad\": d_td_sem,\n",
    "            \"A_Fourier_V\": A_f_mean,\n",
    "            \"A_Fourier_SEM_V\": A_f_sem,\n",
    "            \"delta_Fourier_rad\": d_f_mean,\n",
    "            \"delta_Fourier_SEM_rad\": d_f_sem,\n",
    "            \"Hmag_VperV\": H_mean\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"f_Hz\").reset_index(drop=True)\n",
    "\n",
    "def write_batch_outputs(outdir: Path, res: pd.DataFrame, title_suffix: str, f_fmt: str):\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ## Save CSV\n",
    "    (outdir/\"extracted_summary.csv\").write_text(res.to_csv(index=False), encoding=\"utf-8\")\n",
    "\n",
    "    f = res[\"f_Hz\"].to_numpy()\n",
    "\n",
    "    ## Time domain analusis plots\n",
    "    plt.figure()\n",
    "    plt.errorbar(f, res[\"A_TD_V\"], yerr=res[\"A_TD_SEM_V\"], fmt='o-', capsize=3)\n",
    "    plt.xlabel(\"Driving frequency f (Hz)\")\n",
    "    plt.ylabel(\"Steady-state response amplitude (V)\")\n",
    "    plt.title(f\"Response amplitude vs driving frequency (Time-domain sine fit){title_suffix}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"TD_plot_amplitude_vs_frequency.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(f, res[\"delta_TD_rad\"], yerr=res[\"delta_TD_SEM_rad\"], fmt='o-', capsize=3)\n",
    "    plt.xlabel(\"Driving frequency f (Hz)\")\n",
    "    plt.ylabel(\"Phase difference δ (rad)\")\n",
    "    plt.title(f\"Phase difference vs driving frequency (Time-domain sine fit){title_suffix}\")\n",
    "    phase_ticks(plt.gca(), 'y')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"TD_plot_phase_vs_frequency.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(res[\"delta_TD_rad\"], res[\"A_TD_V\"],\n",
    "                xerr=res[\"delta_TD_SEM_rad\"], yerr=res[\"A_TD_SEM_V\"],\n",
    "                fmt='o-', capsize=3)\n",
    "    plt.xlabel(\"Phase difference δ (rad)\")\n",
    "    plt.ylabel(\"Steady-state response amplitude (V)\")\n",
    "    plt.title(f\"Response amplitude vs phase difference (Time-domain sine fit){title_suffix}\")\n",
    "    phase_ticks(plt.gca(), 'x')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"TD_plot_amplitude_vs_phase.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    ## Fast Fourier Transform plots\n",
    "    plt.figure()\n",
    "    plt.errorbar(f, res[\"A_Fourier_V\"], yerr=res[\"A_Fourier_SEM_V\"], fmt='s-', capsize=3)\n",
    "    plt.xlabel(\"Driving frequency f (Hz)\")\n",
    "    plt.ylabel(\"Steady-state response amplitude (V)\")\n",
    "    plt.title(f\"Response amplitude vs driving frequency (Fourier projection at f){title_suffix}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"Fourier_plot_amplitude_vs_frequency.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(f, res[\"delta_Fourier_rad\"], yerr=res[\"delta_Fourier_SEM_rad\"], fmt='s-', capsize=3)\n",
    "    plt.xlabel(\"Driving frequency f (Hz)\")\n",
    "    plt.ylabel(\"Phase difference δ (rad)\")\n",
    "    plt.title(f\"Phase difference vs driving frequency (Fourier projection at f){title_suffix}\")\n",
    "    phase_ticks(plt.gca(), 'y')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"Fourier_plot_phase_vs_frequency.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(res[\"delta_Fourier_rad\"], res[\"A_Fourier_V\"],\n",
    "                xerr=res[\"delta_Fourier_SEM_rad\"], yerr=res[\"A_Fourier_SEM_V\"],\n",
    "                fmt='s-', capsize=3)\n",
    "    plt.xlabel(\"Phase difference δ (rad)\")\n",
    "    plt.ylabel(\"Steady-state response amplitude (V)\")\n",
    "    plt.title(f\"Response amplitude vs phase difference (Fourier projection at f){title_suffix}\")\n",
    "    phase_ticks(plt.gca(), 'x')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(outdir/\"Fourier_plot_amplitude_vs_phase.png\", dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "## main function that calls all those above\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_folder\", type=str, default=\".\", help=\"Folder containing CSV files.\")\n",
    "    ap.add_argument(\"--output_folder\", type=str, default=\"outputs\", help=\"Where to write batch outputs.\")\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "\n",
    "    folder = Path(args.data_folder)\n",
    "    outroot = Path(args.output_folder)\n",
    "\n",
    "    # Batch definitions\n",
    "    batches = [\n",
    "        (\"batch1\", 0.50, 1.20, \" — coarse sweep\", \".2f\"),\n",
    "        (\"batch2\", 0.80, 0.90, \" — zoom near resonance\", \".2f\"),\n",
    "        (\"batch3\", 0.860, 0.875, \" — fine scan near resonance\", \".3f\"),\n",
    "    ]\n",
    "\n",
    "    for name, fmin, fmax, suffix, fmt in batches:\n",
    "        files = select_files_in_range(folder, fmin, fmax)\n",
    "        if not files:\n",
    "            print(f\"[WARN] {name}: no files found in range [{fmin}, {fmax}] Hz\")\n",
    "            continue\n",
    "        res = process_batch(files)\n",
    "        write_batch_outputs(outroot/name, res, suffix, fmt)\n",
    "        print(f\"[OK] {name}: processed {len(res)} frequencies -> {outroot/name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
